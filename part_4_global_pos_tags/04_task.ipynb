{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9541d5-d3a0-4256-a8cf-8fa5a4fca705",
   "metadata": {},
   "source": [
    "# PART 4: POS Tagging on a non-English language\n",
    "\n",
    "_by Nicolas Bessone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.taggers import PatternTagger\n",
    "\n",
    "import skweak\n",
    "\n",
    "from scripts.skweak_ner_eval import evaluate\n",
    "from scripts.utils import load_data_split, get_frequent_words, tag_all, penntreebank2universal, compute_recall, compute_num_conflicts\n",
    "\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4efa2381bdd1d1cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 330.3 kB/s eta 0:00:39\n",
      "     --------------------------------------- 0.0/12.8 MB 393.8 kB/s eta 0:00:33\n",
      "     ---------------------------------------- 0.2/12.8 MB 1.1 MB/s eta 0:00:12\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 0.9/12.8 MB 3.7 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 1.1/12.8 MB 4.3 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 1.3/12.8 MB 4.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 4.4 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.3/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.6/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 5.3 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 6.5 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 6.9 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.1/12.8 MB 7.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.5/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.7/12.8 MB 8.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.9/12.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.8/12.8 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.0/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.5/12.8 MB 12.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.8/12.8 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 0.0/42.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/42.8 MB 640.0 kB/s eta 0:01:07\n",
      "     --------------------------------------- 0.0/42.8 MB 393.8 kB/s eta 0:01:49\n",
      "     --------------------------------------- 0.1/42.8 MB 573.4 kB/s eta 0:01:15\n",
      "     ---------------------------------------- 0.2/42.8 MB 1.3 MB/s eta 0:00:34\n",
      "      --------------------------------------- 0.6/42.8 MB 2.6 MB/s eta 0:00:17\n",
      "      --------------------------------------- 0.9/42.8 MB 3.3 MB/s eta 0:00:13\n",
      "     - -------------------------------------- 1.3/42.8 MB 4.1 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 1.7/42.8 MB 4.4 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 2.2/42.8 MB 5.0 MB/s eta 0:00:09\n",
      "     -- ------------------------------------- 2.8/42.8 MB 5.8 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 2.8/42.8 MB 5.8 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 3.1/42.8 MB 5.3 MB/s eta 0:00:08\n",
      "     --- ------------------------------------ 3.6/42.8 MB 5.8 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 3.8/42.8 MB 5.7 MB/s eta 0:00:07\n",
      "     --- ------------------------------------ 4.1/42.8 MB 5.8 MB/s eta 0:00:07\n",
      "     ---- ----------------------------------- 4.7/42.8 MB 6.0 MB/s eta 0:00:07\n",
      "     ----- ---------------------------------- 5.8/42.8 MB 7.1 MB/s eta 0:00:06\n",
      "     ------ --------------------------------- 7.0/42.8 MB 8.1 MB/s eta 0:00:05\n",
      "     ------- -------------------------------- 8.2/42.8 MB 8.8 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 9.5/42.8 MB 9.8 MB/s eta 0:00:04\n",
      "     --------- ----------------------------- 10.6/42.8 MB 12.6 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 12.0/42.8 MB 15.2 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 13.2/42.8 MB 18.7 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 14.3/42.8 MB 22.6 MB/s eta 0:00:02\n",
      "     -------------- ------------------------ 15.6/42.8 MB 24.2 MB/s eta 0:00:02\n",
      "     --------------- ----------------------- 16.8/42.8 MB 24.2 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 18.0/42.8 MB 25.1 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 19.2/42.8 MB 25.1 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 20.3/42.8 MB 24.2 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 20.5/42.8 MB 22.6 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 21.5/42.8 MB 21.8 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 22.0/42.8 MB 21.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 22.9/42.8 MB 19.8 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 23.8/42.8 MB 19.3 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 23.9/42.8 MB 19.9 MB/s eta 0:00:01\n",
      "     --------------------- ----------------- 23.9/42.8 MB 17.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 24.7/42.8 MB 16.0 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 25.3/42.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 26.3/42.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 26.6/42.8 MB 15.2 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 27.1/42.8 MB 14.2 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 27.4/42.8 MB 13.4 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 27.7/42.8 MB 12.8 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 28.3/42.8 MB 12.6 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 29.0/42.8 MB 12.4 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 29.8/42.8 MB 11.9 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 30.6/42.8 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------------- ---------- 31.0/42.8 MB 11.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 31.5/42.8 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 31.8/42.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 32.4/42.8 MB 11.1 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 33.4/42.8 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 34.2/42.8 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 34.9/42.8 MB 12.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 35.6/42.8 MB 12.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 36.6/42.8 MB 12.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 37.3/42.8 MB 13.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 38.1/42.8 MB 14.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 38.8/42.8 MB 14.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 39.5/42.8 MB 14.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 40.3/42.8 MB 14.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 41.0/42.8 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  41.7/42.8 MB 16.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.4/42.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 16.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 42.8/42.8 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.11)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.4.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nhbes\\anaconda3\\envs\\limited\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\nhbes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd374d-47a9-4d0a-abac-316250269587",
   "metadata": {},
   "source": [
    "## POS tags\n",
    "\n",
    "For this tutorial, we will use the following subset of the [universal POS tags](https://universaldependencies.org/u/pos/index.html):\n",
    "1. **DET**: determiner, which is a word that modifies nouns or noun phrases and expresses the reference of the noun phrase in context.\n",
    "2. **NUM**: numeral. It is a word that expresses a number and a relation to the number, such as quantity, sequence, frequency or fraction.\n",
    "3. **PROPN**: proper noun is a noun that is the name of a specific individual, place, or object.\n",
    "4. **ADJ**: adjective, which is a word that typically modifies nouns and specifies their properties or attributes.\n",
    "5. **NOUN**: noun, which is a part of speech typically denoting a person, place, thing, animal or idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a21f417219cacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [\"DET\", \"NUM\", \"PROPN\", \"ADJ\", \"NOUN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b562f0c-c762-44c3-ab5e-c8d1e53227ee",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We will use the [English corpus](https://universaldependencies.org/treebanks/en_ewt/index.html) from Universal Dependencies, a framework that contains consistent grammatical annotations across many different languages.\n",
    "The texts in the corpus come from five types of web media: weblogs, newsgroups, emails, reviews, and Yahoo! answers and consist of 254,825 words and 16,621 sentences.\n",
    "\n",
    "Skweak operates on spaCy ``doc`` objects, so the dataset is loaded in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e61c0c38-5a9a-4a00-9649-b1b7464a59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_docs = load_data_split(\"train\", all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1068ab32-f22d-40ea-9cfd-2e34131dc608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Además se le pediría a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    empresas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    interesadas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " en prestar \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    servicio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " que se hagan \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cargo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    señalización\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cartelería\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " que contiene \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    información\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    los\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    usuarios\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Producto\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " del \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " del \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    imperio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    invasiones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    germanas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    población\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    isleña\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " cayó a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    millón\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " durante \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    período\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sajón\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       ", permaneciendo hasta \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    siglo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    XI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " cuando volvió a aumentar llegando a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    7\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    millones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " en \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    siglo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    XV\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       ", pero tras \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    peste\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    negra\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " volvió a reducirse a solo \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    millones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MADRID\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    EUROPA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ") \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    tenistas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    españolas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Anabel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Medina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Carla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Suárez\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    María\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    José\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Martínez\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nuria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Llagostera\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Arantxa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Parra\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lourdes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Domínguez\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " han decidido retirar \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    su\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    plante\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " para disputar \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    próxima\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ADJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    eliminatoria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Copa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Federación\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " tras llegar a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    un\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    acuerdo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " con \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Federación\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Española\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tenis\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    RFET\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ") después de más de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cuatro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    horas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reunión\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " en \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Consejo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Superior\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Deportes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " (CSD) con \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mediación\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " del \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    secretario\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Estado\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Deporte\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jaime\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lissavetzky\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROPN</span>\n",
       "</mark>\n",
       ". </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in train_docs[:3]:\n",
    "    skweak.utils.display_entities(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbbfa7b-9fbf-4c26-9512-f92aa2b35c02",
   "metadata": {},
   "source": [
    "## 3.1 Labeling functions\n",
    "\n",
    "In the first step, we find the 200 most frequent words in our training corpus and use a lexicon to label these words. In the second step, we mannually annotate the 50 most frequent words.\n",
    "Finally, for each POS tag we will create the following labeling functions: \n",
    "\n",
    "*   DET --> Lexicon with determiners.\n",
    "*   NUM --> If the token is a number or a word indicating a number from 1 to 10.\n",
    "*   PROPN --> A word that is capitalized.\n",
    "*   ADJ --> List of prefixes and suffixes. Syntactic rules that check: 1. if the previous word is a form of \"be\" and 2. if the previous word is a determiner or numeral.\n",
    "*   NOUN --> List of prefixes and suffixes. Syntactic rule checking if the previous word is a determiner, numeral or adjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071eda5-6faf-43dc-ad4f-169aaa94e251",
   "metadata": {},
   "source": [
    "#### Lexicon LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3ff73f-4151-4abf-975a-8139ceb7a10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'el', 'en', 'que']\n"
     ]
    }
   ],
   "source": [
    "# Get the 200 most frequent words in the training set\n",
    "frequent_words = get_frequent_words(train_docs, 200)\n",
    "print(frequent_words[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e20d614-94d6-4f45-a006-f1e87a6f9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lexicon\n",
    "with open(\"noun_vb_adj_spanish.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Create a dictionary with the words and their pos tags\n",
    "lexicon = {}\n",
    "for l in lines:\n",
    "    values = l.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "    lexicon[values[0]] = values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad9db7c-35f2-488a-b0e7-c18e0aa94833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 594 words in the lexicon.\n",
      "[('ser', 'VERB'), ('haber', 'VERB'), ('tener', 'VERB'), ('poder', 'VERB'), ('estar', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(lexicon), \"words in the lexicon.\")\n",
    "print(list(lexicon.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db38ff17-3440-46f3-a017-ec7a0823c7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many of the frequent words we found exist in the lexicon\n",
    "len((list(set(frequent_words) & set(list(lexicon.keys())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "722aefef-ed00-4c25-bf29-0d39a6db0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon LF\n",
    "def frequent_word_detector(doc):\n",
    "    for token in doc:\n",
    "        # If the frequent word exists in the lexicon use its assigned pos tag\n",
    "        if token.text.lower() in frequent_words and token.text.lower() in list(lexicon.keys()):\n",
    "            yield token.i, token.i + 1, lexicon[token.text.lower()]\n",
    "\n",
    "\n",
    "lexicon_lf = skweak.heuristics.FunctionAnnotator(\"frequent_words\", frequent_word_detector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2252eb22-0fa6-4e01-b8a3-f28fdc909314",
   "metadata": {},
   "source": [
    "#### Manual annotation LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17544d20-5048-490f-afd8-b1a6b96e53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'el', 'en', 'que', 'los', 'del', 'se', 'un', 'por', 'con', 'una', 'las', 'es', 'su', 'para', 'al', 'como', 'fue', 'más', 'lo', 'sus', 'este', 'ha', 'pero', 'también', 'esta', 'entre', 'son', 'dos', 'le', 'muy', 'años', 'desde', 'año', 'hasta', 'era', 'sobre', 'durante', 'ser', 'eran', 'sin', 'donde', 'ya', 'está', 'tiene', 'parte', 'población', 'km', 'ciudad']\n"
     ]
    }
   ],
   "source": [
    "# Manual annotation\n",
    "top50_words = get_frequent_words(train_docs, 50)\n",
    "print(top50_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2e8c900-324c-4694-b153-fbc14bcb5566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'DET', 'la': 'DET', 'el': 'DET', 'en': 'DET', 'que': 'DET', 'los': 'DET', 'del': 'DET', 'se': 'DET', 'un': 'NUM', 'por': 'DET', 'con': 'DET', 'una': 'NUM', 'las': 'DET', 'es': 'DET', 'su': 'DET', 'para': 'DET', 'al': 'DET', 'como': 'DET', 'fue': 'DET', 'más': 'DET', 'lo': 'DET', 'sus': 'DET', 'este': 'DET', 'ha': 'DET', 'pero': 'DET', 'también': 'DET', 'esta': 'DET', 'entre': 'DET', 'son': 'DET', 'dos': 'NUM', 'le': 'DET', 'muy': 'DET', 'años': 'NOUN', 'desde': 'DET', 'año': 'NOUN', 'hasta': 'DET', 'era': 'DET', 'sobre': 'DET', 'durante': 'DET', 'ser': 'DET', 'eran': 'DET', 'sin': 'DET', 'donde': 'PROPN', 'ya': 'DET', 'está': 'DET', 'tiene': 'DET', 'parte': 'NOUN', 'población': 'NOUN', 'km': 'NOUN', 'ciudad': 'NOUN'}\n"
     ]
    }
   ],
   "source": [
    "manual_tags = {\n",
    "    'de': 'DET',\n",
    "    'la': 'DET',\n",
    "    'el': 'DET',\n",
    "    'en': 'DET',\n",
    "    'que': 'DET',\n",
    "    'los': 'DET',\n",
    "    'del': 'DET',\n",
    "    'se': 'DET',\n",
    "    'un': 'NUM',\n",
    "    'por': 'DET',\n",
    "    'con': 'DET',\n",
    "    'una': 'NUM',\n",
    "    'las': 'DET',\n",
    "    'es': 'DET',\n",
    "    'su': 'DET',\n",
    "    'para': 'DET',\n",
    "    'al': 'DET',\n",
    "    'como': 'DET',\n",
    "    'fue': 'DET',\n",
    "    'más': 'DET',\n",
    "    'lo': 'DET',\n",
    "    'sus': 'DET',\n",
    "    'este': 'DET',\n",
    "    'ha': 'DET',\n",
    "    'pero': 'DET',\n",
    "    'también': 'DET',\n",
    "    'esta': 'DET',\n",
    "    'entre': 'DET',\n",
    "    'son': 'DET',\n",
    "    'dos': 'NUM',\n",
    "    'le': 'DET',\n",
    "    'muy': 'DET',\n",
    "    'años': 'NOUN',\n",
    "    'desde': 'DET',\n",
    "    'año': 'NOUN',\n",
    "    'hasta': 'DET',\n",
    "    'era': 'DET',\n",
    "    'sobre': 'DET',\n",
    "    'durante': 'DET',\n",
    "    'ser': 'DET',\n",
    "    'eran': 'DET',\n",
    "    'sin': 'DET',\n",
    "    'donde': 'PROPN',\n",
    "    'ya': 'DET',\n",
    "    'está': 'DET',\n",
    "    'tiene': 'DET',\n",
    "    'parte': 'NOUN',\n",
    "    'población': 'NOUN',\n",
    "    'km': 'NOUN',\n",
    "    'ciudad': 'NOUN'\n",
    "}\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(manual_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9558b408-4ef9-4a2f-a3aa-fa22532b2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual POS tags LF\n",
    "def manual_pos_tagger(doc):\n",
    "    for token in doc:\n",
    "        if token.text.lower() in manual_tags:\n",
    "            yield token.i, token.i + 1, manual_tags[token.text.lower()]\n",
    "\n",
    "\n",
    "manual_pos_lf = skweak.heuristics.FunctionAnnotator(\"manual_pos\", manual_pos_tagger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d654a-0f2e-4f7c-9b72-1a790de0e564",
   "metadata": {},
   "source": [
    "#### DET LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f5808a-053e-4d82-87b7-c7a58d776087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from det_spanish.json\n",
      "Populating trie for class DET (number: 142)\n"
     ]
    }
   ],
   "source": [
    "# Use a lexicon of determiners\n",
    "tries = skweak.gazetteers.extract_json_data(\"det_spanish.json\")\n",
    "det_lf = skweak.gazetteers.GazetteerAnnotator(\"determiners\", tries, case_sensitive=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7533e-b027-4753-8eae-03df346efa67",
   "metadata": {},
   "source": [
    "#### NUM LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eeb92f1-b25d-4f8f-8d13-73ede592fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a regular expression pattern to look for digits\n",
    "def num_detector(doc):\n",
    "    for token in doc:\n",
    "        if re.search(\"\\d+\", token.text):\n",
    "            yield token.i, token.i + 1, \"NUM\"\n",
    "\n",
    "# Check if the token is the word of a number from 1 to 10\n",
    "def num_word_detector(doc):\n",
    "    for token in doc:\n",
    "        if token.text.lower() in [\"uno\", \"dos\", \"tres\", \"cuatro\", \"cinco\", \"seis\", \"siete\", \"ocho\", \"nueve\", \"diez\"]:\n",
    "            yield token.i, token.i + 1, \"NUM\"\n",
    "\n",
    "num_lf1 = skweak.heuristics.FunctionAnnotator(\"numerals1\", num_detector)\n",
    "num_lf2 = skweak.heuristics.FunctionAnnotator(\"numerals2\", num_word_detector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f6c463-33dc-45aa-a4c3-e206f01a1558",
   "metadata": {},
   "source": [
    "#### PROPN LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87790367-e082-4a2d-a794-24ed64ac55a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the fist letter of a word or the whole word is capitalized\n",
    "def propn_detector(doc):\n",
    "    for token in doc:\n",
    "        if token.i == 0:\n",
    "            # For the first word of a sentence, check if all letters are capitalized\n",
    "            if token.text.isupper():\n",
    "                yield token.i, token.i + 1, \"PROPN\"\n",
    "        else:\n",
    "            if token.text.isupper() or token.text[0].isupper():\n",
    "                yield token.i, token.i + 1, \"PROPN\"\n",
    "\n",
    "\n",
    "propn_lf = skweak.heuristics.FunctionAnnotator(\"proper_nouns\", propn_detector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a8181f-da19-4c11-9636-79f95892025d",
   "metadata": {},
   "source": [
    "#### ADJ LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e24c251-3ec5-49e4-91fb-c1ed20848963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look for common suffixes and prefixes\n",
    "def adj_detector_suffixes(doc):\n",
    "    #suffixes = (\"able\", \"al\", \"ful\", \"ic\", \"ive\", \"less\", \"ous\", \"y\", \"ish\", \"ible\", \"ent\", \"est\")\n",
    "    suffixes = (\"ción\", \"dad\", \"aje\", \"ista\", \"ante\", \"or\", \"ista\", \"ero\", \"ista\", \"oso\", \"ante\", \"ible\", \"al\", \"oso\", \"ino\", \"oso\", \"ar\", \"er\", \"ir\", \"ar\", \"er\", \"ir\", \"mente\", \"mente\", \"mente\", \"ito\", \"ita\", \"illo\", \"illa\")\n",
    "\n",
    "    for token in doc:\n",
    "        if len(token.text) > 3 and token.text.endswith(suffixes):\n",
    "            yield token.i, token.i + 1, \"ADJ\"\n",
    "\n",
    "\n",
    "# Look for common prefixes\n",
    "def adj_detector_prefixes(doc):\n",
    "    #prefixes = (\"un\", \"im\", \"in\", \"ir\", \"il\", \"non\", \"dis\")\n",
    "    prefixes = (\"des\", \"re\", \"pre\", \"ex\", \"anti\", \"sub\", \"trans\", \"pos\", \"bi\", \"tri\", \"multi\")\n",
    "    for token in doc:\n",
    "        if len(token.text) > 3 and token.text.lower().startswith(prefixes):\n",
    "            yield token.i, token.i + 1, \"ADJ\"\n",
    "\n",
    "\n",
    "# If the previous word is a form of \"be\" and the current word does not end with \"ing\" and was not labeled as DET, then it's an adjective\n",
    "def adj_detector_synt1(doc):\n",
    "    palabras_clave_ser = [\"ser\", \"soy\", \"eres\", \"es\", \"somos\", \"sois\", \"son\", \"fui\", \"fuiste\", \"fue\", \"fuimos\", \"fuisteis\", \"fueron\", \"era\", \"eras\", \"éramos\", \"erais\", \"eran\"]\n",
    "    weak_labels = [\"O\"] * len(doc)\n",
    "    for span in doc.spans[\"determiners\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for token in doc[1:]:\n",
    "        if not token.is_punct:\n",
    "            prev = doc[token.i - 1].text.lower()\n",
    "            #if prev in [\"be\", \"been\", \"being\", \"am\", \"is\", \"are\", \"was\", \"were\"] and (\n",
    "            #        not token.text.endswith(\"ing\")) and weak_labels[token.i] == \"O\":\n",
    "            #    yield token.i, token.i + 1, \"ADJ\"\n",
    "        if token.text.lower() in palabras_clave_ser and (not token.text.endswith(\"ando\") or not token.text.endswith(\"iendo\")) and weak_labels[token.i] == \"O\":\n",
    "            yield token.i, token.i + 1, \"ADJ\"\n",
    "            \n",
    "# If the previous word is labeld as DET or NUM, then the current word is an adjective\n",
    "def adj_detector_synt2(doc):\n",
    "    weak_labels = [\"O\"] * len(doc)\n",
    "\n",
    "    for span in doc.spans[\"determiners\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"numerals1\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"numerals2\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for token in doc[1:]:\n",
    "        if not token.is_punct:\n",
    "            if weak_labels[token.i - 1] != \"O\":\n",
    "                yield token.i, token.i + 1, \"ADJ\"\n",
    "\n",
    "\n",
    "adj_lf1 = skweak.heuristics.FunctionAnnotator(\"adjectives1\", adj_detector_suffixes)\n",
    "adj_lf2 = skweak.heuristics.FunctionAnnotator(\"adjectives2\", adj_detector_prefixes)\n",
    "adj_lf3 = skweak.heuristics.FunctionAnnotator(\"adjectives3\", adj_detector_synt1)\n",
    "adj_lf4 = skweak.heuristics.FunctionAnnotator(\"adjectives4\", adj_detector_synt2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f2b5d4-9834-40f8-bad6-b5a347f4a457",
   "metadata": {},
   "source": [
    "#### NOUN LF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25391729-012c-4069-b44f-426ce24f3c2d",
   "metadata": {},
   "source": [
    "Let's create a labeling function that looks for common noun suffixes. Can you think of some?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eceff82-36ec-4ac6-9aeb-64db0b57e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***********************************\n",
    "def noun_detector_suffixes(doc):\n",
    "    suffixes = (\"ción\", \"dad\", \"dor\", \"dad\", \"ismo\", \"miento\", \"ción\", \"aje\", \"ería\", \"ez\")\n",
    "    for token in doc:\n",
    "        if len(token.text) > 3 and token.text.endswith(suffixes):\n",
    "            yield token.i, token.i + 1, \"NOUN\"\n",
    "    \n",
    "# ***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c00243b-f55c-4b29-a3d2-bf6a23494253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for common prefixes\n",
    "def noun_detector_prefixes(doc):\n",
    "    prefixes = (\n",
    "        \"anti\", \"auto\", \"bi\", \"co\", \"counter\", \"dis\", \"ex\", \"hyper\", \"in\", \"inter\", \"kilo\", \"mal\", \"mega\", \"mis\",\n",
    "        \"mini\", \"mono\", \"neo\", \"out\", \"poly\", \"pseudo\", \"re\", \"semi\", \"sub\", \"super\", \"sur\", \"tele\", \"tri\", \"ultra\",\n",
    "        \"under\", \"vice\")\n",
    "    for token in doc:\n",
    "        if len(token.text) > 3 and token.text.lower().startswith(prefixes):\n",
    "            yield token.i, token.i + 1, \"NOUN\"\n",
    "\n",
    "\n",
    "# # If the previous word is labeld as DET, NUM or ADJ, then the current word is an noun\n",
    "def noun_detector_synt(doc):\n",
    "    weak_labels = [\"O\"] * len(doc)\n",
    "\n",
    "    for span in doc.spans[\"determiners\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"numerals1\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"numerals2\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"adjectives1\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"adjectives2\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"adjectives3\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for span in doc.spans[\"adjectives4\"]:\n",
    "        weak_labels[span.start] = span.label_\n",
    "\n",
    "    for token in doc[1:]:\n",
    "        if not token.is_punct:\n",
    "            if weak_labels[token.i - 1] != \"O\":\n",
    "                yield token.i, token.i + 1, \"NOUN\"\n",
    "\n",
    "\n",
    "noun_lf1 = skweak.heuristics.FunctionAnnotator(\"nouns1\", noun_detector_suffixes)\n",
    "noun_lf2 = skweak.heuristics.FunctionAnnotator(\"nouns2\", noun_detector_prefixes)\n",
    "noun_lf3 = skweak.heuristics.FunctionAnnotator(\"nouns3\", noun_detector_synt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8993d97-1611-4048-8392-4d4abb89e645",
   "metadata": {},
   "source": [
    "## Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c62dd04d953cc2ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Put all LFs in a list\n",
    "lfs = [\n",
    "    lexicon_lf, manual_pos_lf, det_lf, \n",
    "    num_lf1, num_lf2, propn_lf,\n",
    "    adj_lf1, adj_lf2, adj_lf3, adj_lf4,\n",
    "    noun_lf2, noun_lf3\n",
    "]\n",
    "\n",
    "train_docs = tag_all(train_docs, lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94d611f-e687-4e8e-8636-4b6bdbd818dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Además se le pediría a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " empresas \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    interesadas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " en prestar \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " servicio que se hagan cargo de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " señalización y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " cartelería que \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    contiene\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    información\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    los\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " usuarios. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Producto del fin del imperio y \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    invasiones\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " germanas \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " población isleña cayó a 1 millón durante \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " período sajón, permaneciendo hasta \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " siglo XI cuando volvió a aumentar llegando a 5 a 7 millones en \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " siglo XV, pero tras \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " peste negra volvió a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reducirse\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " a solo 2 a 4 millones. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">MADRID, 3 (EUROPA PRESS) \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Las\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " tenistas españolas Anabel Medina, Carla Suárez, María José Martínez, Nuria Llagostera, Arantxa Parra y Lourdes Domínguez han decidido \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    retirar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    su\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " plante para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    disputar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " próxima eliminatoria de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Copa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " Federación tras llegar a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    un\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " acuerdo con \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " Federación Española de Tenis (RFET) después de más de cuatro horas de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    reunión\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " en \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Consejo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Superior\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NOUN</span>\n",
       "</mark>\n",
       " de Deportes (CSD) con \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    la\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " mediación del secretario de Estado para \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    el\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DET</span>\n",
       "</mark>\n",
       " Deporte, Jaime Lissavetzky. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print some of the assigned weak labels\n",
    "for doc in train_docs[:3]:\n",
    "    skweak.utils.display_entities(doc, [\"determiners\", \"nouns2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41c269d6-1a2d-4ac6-8a2b-b78ce149f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1\n",
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Number of processed documents: 3000\n",
      "Number of processed documents: 4000\n",
      "Number of processed documents: 5000\n",
      "Number of processed documents: 6000\n",
      "Number of processed documents: 7000\n",
      "Number of processed documents: 8000\n",
      "Number of processed documents: 9000\n",
      "Number of processed documents: 10000\n",
      "Number of processed documents: 11000\n",
      "Number of processed documents: 12000\n",
      "Number of processed documents: 13000\n",
      "Number of processed documents: 14000\n",
      "Finished E-step with 14187 documents\n",
      "Starting iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1    -1115622.4238             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Number of processed documents: 3000\n",
      "Number of processed documents: 4000\n",
      "Number of processed documents: 5000\n",
      "Number of processed documents: 6000\n",
      "Number of processed documents: 7000\n",
      "Number of processed documents: 8000\n",
      "Number of processed documents: 9000\n",
      "Number of processed documents: 10000\n",
      "Number of processed documents: 11000\n",
      "Number of processed documents: 12000\n",
      "Number of processed documents: 13000\n",
      "Number of processed documents: 14000\n",
      "Finished E-step with 14187 documents\n",
      "Starting iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2    -1046195.5699      +69426.8539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Number of processed documents: 3000\n",
      "Number of processed documents: 4000\n",
      "Number of processed documents: 5000\n",
      "Number of processed documents: 6000\n",
      "Number of processed documents: 7000\n",
      "Number of processed documents: 8000\n",
      "Number of processed documents: 9000\n",
      "Number of processed documents: 10000\n",
      "Number of processed documents: 11000\n",
      "Number of processed documents: 12000\n",
      "Number of processed documents: 13000\n",
      "Number of processed documents: 14000\n",
      "Finished E-step with 14187 documents\n",
      "Starting iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3     -995387.0434      +50808.5265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Number of processed documents: 3000\n",
      "Number of processed documents: 4000\n",
      "Number of processed documents: 5000\n",
      "Number of processed documents: 6000\n",
      "Number of processed documents: 7000\n",
      "Number of processed documents: 8000\n",
      "Number of processed documents: 9000\n",
      "Number of processed documents: 10000\n",
      "Number of processed documents: 11000\n",
      "Number of processed documents: 12000\n",
      "Number of processed documents: 13000\n",
      "Number of processed documents: 14000\n",
      "Finished E-step with 14187 documents\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         4     -957274.6232      +38112.4202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Number of processed documents: 3000\n",
      "Number of processed documents: 4000\n",
      "Number of processed documents: 5000\n",
      "Number of processed documents: 6000\n",
      "Number of processed documents: 7000\n",
      "Number of processed documents: 8000\n",
      "Number of processed documents: 9000\n",
      "Number of processed documents: 10000\n",
      "Number of processed documents: 11000\n",
      "Number of processed documents: 12000\n",
      "Number of processed documents: 13000\n",
      "Number of processed documents: 14000\n",
      "Finished E-step with 14187 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5     -937772.9840      +19501.6392\n"
     ]
    }
   ],
   "source": [
    "# Train HMM\n",
    "hmm = skweak.aggregation.HMM(\"hmm\", all_labels)\n",
    "hmm = hmm.fit(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc0fe7d6-081c-4e01-96b5-45da566cbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority voting\n",
    "mv = skweak.aggregation.MajorityVoter(\"mv\", all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9276ba55-6b54-4447-8d74-b14c3c3376c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LFs, HMM and MV to the test docs\n",
    "test_docs = load_data_split(\"test\", all_labels)\n",
    "test_docs = tag_all(test_docs, lfs + [mv, hmm])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408db9c-0773-4cbb-9d38-428fb4d66c52",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163aa41-49be-4f34-a72a-3272cab0fab9",
   "metadata": {},
   "source": [
    "#### Which POS tags are easier to detect?\n",
    "\n",
    "* We see that POS tags like determiners and numerals are easier to detect and we can achieve a good F1 score with just one or two simple LFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a2a542c-754b-4c74-a4c5-ce178e4434b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluate(test_docs, all_labels, [\n",
    "    \"determiners\", \"numerals1\", \"numerals2\", \"proper_nouns\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a140604-c1b9-4966-9c6e-36c7637794fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok_precision</th>\n",
       "      <th>tok_recall</th>\n",
       "      <th>tok_f1</th>\n",
       "      <th>tok_cee</th>\n",
       "      <th>tok_acc</th>\n",
       "      <th>coverage</th>\n",
       "      <th>ent_precision</th>\n",
       "      <th>ent_recall</th>\n",
       "      <th>ent_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>proportion</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DET</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">27.3 %</th>\n",
       "      <th>determiners</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.928</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper_nouns</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">NUM</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">4.2 %</th>\n",
       "      <th>determiners</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals1</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.850</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals2</th>\n",
       "      <td>0.647</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.168</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper_nouns</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">PROPN</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">15.2 %</th>\n",
       "      <th>determiners</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numerals2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper_nouns</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.788</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               tok_precision  tok_recall  tok_f1 tok_cee  \\\n",
       "label proportion model                                                     \n",
       "DET   27.3 %     determiners           0.879       0.985   0.928           \n",
       "                 numerals1             0.000       0.000   0.000           \n",
       "                 numerals2             0.000       0.000   0.000           \n",
       "                 proper_nouns          0.000       0.000   0.000           \n",
       "NUM   4.2 %      determiners           0.000       0.000   0.000           \n",
       "                 numerals1             0.951       0.769   0.850           \n",
       "                 numerals2             0.647       0.096   0.168           \n",
       "                 proper_nouns          0.000       0.000   0.000           \n",
       "PROPN 15.2 %     determiners           0.000       0.000   0.000           \n",
       "                 numerals1             0.000       0.000   0.000           \n",
       "                 numerals2             0.000       0.000   0.000           \n",
       "                 proper_nouns          0.700       0.901   0.788           \n",
       "\n",
       "                              tok_acc coverage  ent_precision  ent_recall  \\\n",
       "label proportion model                                                      \n",
       "DET   27.3 %     determiners                            0.879       0.985   \n",
       "                 numerals1                              0.000       0.000   \n",
       "                 numerals2                              0.000       0.000   \n",
       "                 proper_nouns                           0.000       0.000   \n",
       "NUM   4.2 %      determiners                            0.000       0.000   \n",
       "                 numerals1                              0.951       0.769   \n",
       "                 numerals2                              0.647       0.096   \n",
       "                 proper_nouns                           0.000       0.000   \n",
       "PROPN 15.2 %     determiners                            0.000       0.000   \n",
       "                 numerals1                              0.000       0.000   \n",
       "                 numerals2                              0.000       0.000   \n",
       "                 proper_nouns                           0.700       0.901   \n",
       "\n",
       "                               ent_f1  \n",
       "label proportion model                 \n",
       "DET   27.3 %     determiners    0.928  \n",
       "                 numerals1      0.000  \n",
       "                 numerals2      0.000  \n",
       "                 proper_nouns   0.000  \n",
       "NUM   4.2 %      determiners    0.000  \n",
       "                 numerals1      0.850  \n",
       "                 numerals2      0.168  \n",
       "                 proper_nouns   0.000  \n",
       "PROPN 15.2 %     determiners    0.000  \n",
       "                 numerals1      0.000  \n",
       "                 numerals2      0.000  \n",
       "                 proper_nouns   0.788  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[\"DET\", \"NUM\", \"PROPN\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fb08f-26ba-47ba-983a-ab50500fb3ad",
   "metadata": {},
   "source": [
    "* Other POS tags like adjectives and nouns, which rely more on the context are harder to detect and require more complicated rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c905080-6f03-4e32-9751-b7191d6969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluate(test_docs, all_labels, [\n",
    "    \"adjectives1\", \"adjectives2\", \"adjectives3\", \"adjectives4\",\n",
    "    \"nouns1\", \"nouns2\", \"nouns3\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "590567c9-b9de-42d6-9003-1497740fc7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok_precision</th>\n",
       "      <th>tok_recall</th>\n",
       "      <th>tok_f1</th>\n",
       "      <th>tok_cee</th>\n",
       "      <th>tok_acc</th>\n",
       "      <th>coverage</th>\n",
       "      <th>ent_precision</th>\n",
       "      <th>ent_recall</th>\n",
       "      <th>ent_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>proportion</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">ADJ</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">12.3 %</th>\n",
       "      <th>adjectives1</th>\n",
       "      <td>0.154</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.186</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives2</th>\n",
       "      <td>0.133</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives4</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.104</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">NOUN</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">41.0 %</th>\n",
       "      <th>adjectives1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjectives4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns2</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.206</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nouns3</th>\n",
       "      <td>0.343</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.448</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tok_precision  tok_recall  tok_f1 tok_cee  \\\n",
       "label proportion model                                                    \n",
       "ADJ   12.3 %     adjectives1          0.154       0.238   0.186           \n",
       "                 adjectives2          0.133       0.085   0.104           \n",
       "                 adjectives3          0.000       0.000   0.000           \n",
       "                 adjectives4          0.071       0.192   0.104           \n",
       "                 nouns1               0.000       0.000   0.000           \n",
       "                 nouns2               0.000       0.000   0.000           \n",
       "                 nouns3               0.000       0.000   0.000           \n",
       "NOUN  41.0 %     adjectives1          0.000       0.000   0.000           \n",
       "                 adjectives2          0.000       0.000   0.000           \n",
       "                 adjectives3          0.000       0.000   0.000           \n",
       "                 adjectives4          0.000       0.000   0.000           \n",
       "                 nouns1               0.000       0.000   0.000           \n",
       "                 nouns2               0.392       0.140   0.206           \n",
       "                 nouns3               0.343       0.642   0.448           \n",
       "\n",
       "                             tok_acc coverage  ent_precision  ent_recall  \\\n",
       "label proportion model                                                     \n",
       "ADJ   12.3 %     adjectives1                           0.154       0.238   \n",
       "                 adjectives2                           0.133       0.085   \n",
       "                 adjectives3                           0.000       0.000   \n",
       "                 adjectives4                           0.071       0.192   \n",
       "                 nouns1                                0.000       0.000   \n",
       "                 nouns2                                0.000       0.000   \n",
       "                 nouns3                                0.000       0.000   \n",
       "NOUN  41.0 %     adjectives1                           0.000       0.000   \n",
       "                 adjectives2                           0.000       0.000   \n",
       "                 adjectives3                           0.000       0.000   \n",
       "                 adjectives4                           0.000       0.000   \n",
       "                 nouns1                                0.000       0.000   \n",
       "                 nouns2                                0.392       0.140   \n",
       "                 nouns3                                0.343       0.642   \n",
       "\n",
       "                              ent_f1  \n",
       "label proportion model                \n",
       "ADJ   12.3 %     adjectives1   0.186  \n",
       "                 adjectives2   0.104  \n",
       "                 adjectives3   0.000  \n",
       "                 adjectives4   0.104  \n",
       "                 nouns1        0.000  \n",
       "                 nouns2        0.000  \n",
       "                 nouns3        0.000  \n",
       "NOUN  41.0 %     adjectives1   0.000  \n",
       "                 adjectives2   0.000  \n",
       "                 adjectives3   0.000  \n",
       "                 adjectives4   0.000  \n",
       "                 nouns1        0.000  \n",
       "                 nouns2        0.206  \n",
       "                 nouns3        0.448  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[\"ADJ\", \"NOUN\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838acb79-8c93-41db-b41a-d85c1b41f9a7",
   "metadata": {},
   "source": [
    "#### Which type of LF works the best?\n",
    "\n",
    "* For adjectives the LF that uses suffixes works the best, while the syntactic rules are less accurate. On the contrary, for nouns the LF that is based on syntactic analysis has the best results. For both POS tags, the LFs that use prefixes do not yield good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a0d51-ea4e-4e64-8eae-1c8f832fe6df",
   "metadata": {},
   "source": [
    "#### Which aggregator works best?\n",
    "\n",
    "* Despite its simplicity, majority voting outperforms HMM on almost all of the POS tags and overall achieves a higher macro F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d269f07-026b-4349-80c5-bd9a04a4ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluate(test_docs, all_labels, [\"mv\", \"hmm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd763883-88c7-4517-a97c-91b691826a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok_precision</th>\n",
       "      <th>tok_recall</th>\n",
       "      <th>tok_f1</th>\n",
       "      <th>tok_cee</th>\n",
       "      <th>tok_acc</th>\n",
       "      <th>coverage</th>\n",
       "      <th>ent_precision</th>\n",
       "      <th>ent_recall</th>\n",
       "      <th>ent_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>proportion</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ADJ</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">12.3 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.073</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.106</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.136</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DET</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">27.3 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.885</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.918</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.610</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NOUN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">41.0 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.080</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.353</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.252</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NUM</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.2 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.182</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.728</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PROPN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">15.2 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.756</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.688</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">macro</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.452</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.506</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">micro</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.404</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.414</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.597</td>\n",
       "      <td>1.053</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.442</td>\n",
       "      <td>3.459</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">weighted</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.441</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.432</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.451</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.448</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tok_precision  tok_recall  tok_f1 tok_cee tok_acc  \\\n",
       "label    proportion model                                                      \n",
       "ADJ      12.3 %     hmm            0.073       0.188   0.106                   \n",
       "                    mv             0.117       0.162   0.136                   \n",
       "DET      27.3 %     hmm            0.885       0.954   0.918                   \n",
       "                    mv             0.478       0.839   0.610                   \n",
       "NOUN     41.0 %     hmm            0.095       0.070   0.080                   \n",
       "                    mv             0.353       0.195   0.252                   \n",
       "NUM      4.2 %      hmm            0.706       0.105   0.182                   \n",
       "                    mv             0.920       0.603   0.728                   \n",
       "PROPN    15.2 %     hmm            0.802       0.714   0.756                   \n",
       "                    mv             0.810       0.597   0.688                   \n",
       "macro               hmm            0.512       0.406   0.452                   \n",
       "                    mv             0.536       0.479   0.506                   \n",
       "micro               hmm            0.404       0.425   0.414    4.64   0.597   \n",
       "                    mv             0.438       0.445   0.442   3.459   0.473   \n",
       "weighted            hmm            0.441       0.425   0.432                   \n",
       "                    mv             0.451       0.445   0.448                   \n",
       "\n",
       "                          coverage  ent_precision  ent_recall  ent_f1  \n",
       "label    proportion model                                              \n",
       "ADJ      12.3 %     hmm                     0.073       0.188   0.106  \n",
       "                    mv                      0.117       0.162   0.136  \n",
       "DET      27.3 %     hmm                     0.885       0.954   0.918  \n",
       "                    mv                      0.478       0.839   0.610  \n",
       "NOUN     41.0 %     hmm                     0.095       0.070   0.080  \n",
       "                    mv                      0.353       0.195   0.252  \n",
       "NUM      4.2 %      hmm                     0.706       0.105   0.182  \n",
       "                    mv                      0.920       0.603   0.728  \n",
       "PROPN    15.2 %     hmm                     0.802       0.714   0.756  \n",
       "                    mv                      0.810       0.597   0.688  \n",
       "macro               hmm                     0.512       0.406   0.452  \n",
       "                    mv                      0.536       0.479   0.506  \n",
       "micro               hmm      1.053          0.404       0.425   0.414  \n",
       "                    mv       1.016          0.438       0.445   0.442  \n",
       "weighted            hmm                     0.441       0.425   0.432  \n",
       "                    mv                      0.451       0.445   0.448  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66869e214b73e10",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Using Libraries as Labelling functions\n",
    "\n",
    "\n",
    "In this part, we use popular NLP libraries to create labeling functions. They include Spacy, NLTK, Textblob.\n",
    "We use the Majority Voter and HMM as aggregation functions\n",
    "Optionally, you can train your own model on the data.\n",
    "\n",
    "Learning goals:\n",
    "- Understand how to use external libraries as labeling functions\n",
    "- Understand the Spacy object and how to use it for annotation\n",
    "\n",
    "First, read and understand the two functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d26ad3f38fb269a2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sometimes data formats (here POS tags) differ. We load the data and convert it to the format we need. \n",
    "# Surely, there is some loss of information\n",
    "def nltk_tagger(doc):\n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            # Tag token with nltk\n",
    "            nltk_pos = nltk.pos_tag([token.text])[0][1]\n",
    "            # Map nltk pos tags to ours\n",
    "            if nltk_pos == \"DT\":\n",
    "                yield token.i, token.i + 1, \"DET\"\n",
    "            elif nltk_pos == \"CD\":\n",
    "                yield token.i, token.i + 1, \"NUM\"\n",
    "            elif nltk_pos == \"NNP\" or nltk_pos == \"NNPS\":\n",
    "                yield token.i, token.i + 1, \"PROPN\"\n",
    "            elif nltk_pos == \"JJ\" or nltk_pos == \"JJR\" or nltk_pos == \"JJS\":\n",
    "                yield token.i, token.i + 1, \"ADJ\"\n",
    "            elif nltk_pos == \"NN\" or nltk_pos == \"NNS\":\n",
    "                yield token.i, token.i + 1, \"NOUN\"\n",
    "            elif nltk_pos == \"VB\" or nltk_pos == \"VBD\" or nltk_pos == \"VBG\" or nltk_pos == \"VBN\" or nltk_pos == \"VBP\" or nltk_pos == \"VBZ\":\n",
    "                yield token.i, token.i + 1, \"VERB\"\n",
    "\n",
    "\n",
    "# We cn also use the Textblob library to get POS tags\n",
    "# Under the hood, it uses the Pattern library. Once again, a transformation of the tag-labels is needed\n",
    "def textblob_tagger(doc):\n",
    "    for token in doc:\n",
    "        if not token.is_punct:\n",
    "            textblob_pos = TextBlob(token.text, pos_tagger=PatternTagger()).tags\n",
    "            if len(textblob_pos) > 0:\n",
    "                yield token.i, token.i + 1, penntreebank2universal(textblob_pos[0][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c9785e6266442",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Write the Spacy Labeling Functions\n",
    "\n",
    "Use the two english Spacy models \"en_core_web_sm\", \"en_core_web_md\" to create labeling functions.\n",
    "The challenge is that they use different tokens, i.e. the atomic units of a sentence. Our simple tokenization just splits the words by whitespace.\n",
    "Your task it to design an algorithm that maps the tokens of the simple tokenization to the tokens of the Spacy tokenization, and use the token available there to create labeling functions.\n",
    "\n",
    "Hints:\n",
    "1) Access token i by `token=doc[i]` or obtain its poition by `i=token.i`\n",
    "2) Access the Spacy POS token (its ground truth) by `pos=token.pos_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "315f3e08-1113-4b16-a09a-5bb7020473ed",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eng_nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "eng_nlp_md = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# ***********************************\n",
    "\n",
    "def eng_spacy_tagger_sm(doc):\n",
    "    other_doc = eng_nlp_sm(doc.text)\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "\n",
    "def eng_spacy_tagger_md(doc):\n",
    "    other_doc = eng_nlp_md(doc.text)\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "# ***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44658d0b-d084-424f-84d3-bcc1d5c99cee",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "eng_nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "eng_nlp_md = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# ***********************************\n",
    "\n",
    "def eng_spacy_tagger_sm(doc):\n",
    "    other_doc = eng_nlp_sm(doc.text)\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "\n",
    "def eng_spacy_tagger_md(doc):\n",
    "    other_doc = eng_nlp_md(doc.text)\n",
    "    for token in doc:\n",
    "        labelled = False\n",
    "        for other_token in other_doc:\n",
    "            if other_doc[other_token.i:].text not in doc[token.i:].text:\n",
    "                continue\n",
    "            if token.text in other_token.text and not labelled:\n",
    "                labelled = True\n",
    "                yield token.i, token.i + 1, other_token.pos_.split(\"-\")[-1]\n",
    "# ***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d4fd528-6b38-4ec2-b99f-4876245da3e2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "nltk_lf = skweak.heuristics.FunctionAnnotator(\"nltk\", nltk_tagger)\n",
    "textblob_lf = skweak.heuristics.FunctionAnnotator(\"textblob\", textblob_tagger)\n",
    "eng_spacy_sm_lf = skweak.heuristics.FunctionAnnotator(\"eng_spacy_sm\", eng_spacy_tagger_sm)\n",
    "eng_spacy_md_lf = skweak.heuristics.FunctionAnnotator(\"eng_spacy_md\", eng_spacy_tagger_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f683e3635b65825",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load Data and apply Labeling functions\n",
    "\n",
    "Before and after applying the labeling functions, and the aggregation functions, we compute the recall and number of conflicts. For the sake of time, we use this time only a subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ad74df3-edf7-4e10-9f66-42a9159fc49b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# load training and test data\n",
    "lfs = [nltk_lf, eng_spacy_sm_lf, textblob_lf, eng_spacy_md_lf]\n",
    "all_labels = [\"DET\", \"NUM\", \"PROPN\", \"NOUN\", \"ADJ\"]\n",
    "\n",
    "# small amount of data for the sake of time\n",
    "train_docs = load_data_split(\"train\", all_labels, 3000)\n",
    "\n",
    "# tag the training documents\n",
    "train_docs = tag_all(train_docs, lfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2ccb283b5af19c0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train recall 1.0\n",
      "Train conflicts 0.8035\n"
     ]
    }
   ],
   "source": [
    "recall = compute_recall(train_docs)\n",
    "num_conflicts = compute_num_conflicts(train_docs)\n",
    "print(\"Train recall\", recall)\n",
    "print(\"Train conflicts\", num_conflicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a95f9bf687cbe8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We observe that the recall is very high. This is because the used libraries are quite well.\n",
    "Further, we observe that in 40.5% of the tokens there is a conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3260766620d5732f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 1\n",
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Finished E-step with 3000 documents\n",
      "Starting iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -221402.1693             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Finished E-step with 3000 documents\n",
      "Starting iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2     -216998.1289       +4404.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Finished E-step with 3000 documents\n",
      "Starting iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3     -215905.4287       +1092.7002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Finished E-step with 3000 documents\n",
      "Starting iteration 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         4     -215414.7898        +490.6389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processed documents: 1000\n",
      "Number of processed documents: 2000\n",
      "Finished E-step with 3000 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5     -215178.9114        +235.8785\n"
     ]
    }
   ],
   "source": [
    "# train the HMM\n",
    "hmm = skweak.aggregation.HMM(\"hmm\", all_labels)\n",
    "hmm=hmm.fit(train_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e5e369a339ea5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we compare how majority vote and HMM change the number of conflicts.\n",
    "Remember, that it's important to set Majority vote before HMM, otherwise Majority Vote takes the HMM predictions into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e97248010fd19f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflicts with MV on train set:  0.8035\n"
     ]
    }
   ],
   "source": [
    "mv = skweak.aggregation.MajorityVoter(\"mv\", all_labels)\n",
    "train_docs = tag_all(train_docs, [mv, hmm])\n",
    "\n",
    "num_conflicts = compute_num_conflicts(train_docs)\n",
    "print(\"Conflicts with MV on train set: \", num_conflicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce0ba37f42b099",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "We observe that the number of token conflicts does not change. The reason is that both methods can not choose a class different from the labeling functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4459da2d558cc1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Look at the Precision, Recall and F1-Score of the different aggregation functions. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4e8b6728ab8f9fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflicts on test set 0.8114\n"
     ]
    }
   ],
   "source": [
    "# tag the test documents\n",
    "# Once again, it's important to set Majority vote before HMM, otherwise Majority Vote takes the HMM predictions into account\n",
    "test_docs = load_data_split(\"test\", all_labels, 1000)\n",
    "test_docs = tag_all(test_docs, lfs + [mv, hmm])\n",
    "\n",
    "num_conflicts = compute_num_conflicts(test_docs)\n",
    "print(\"Conflicts on test set\", num_conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8489eca67920c19a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = evaluate(test_docs, all_labels, [ \"mv\", \"hmm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59bedaa1e417ad94",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>tok_precision</th>\n",
       "      <th>tok_recall</th>\n",
       "      <th>tok_f1</th>\n",
       "      <th>tok_cee</th>\n",
       "      <th>tok_acc</th>\n",
       "      <th>coverage</th>\n",
       "      <th>ent_precision</th>\n",
       "      <th>ent_recall</th>\n",
       "      <th>ent_f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>proportion</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ADJ</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">12.3 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.220</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.656</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.156</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DET</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">27.3 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NOUN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">41.0 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.251</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.312</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.285</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.312</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">NUM</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4.2 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.846</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.842</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">PROPN</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">15.2 %</th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.136</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.238</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.216</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">macro</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.420</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.414</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.420</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">micro</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.196</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.254</td>\n",
       "      <td>6.394</td>\n",
       "      <td>0.312</td>\n",
       "      <td>1.829</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.236</td>\n",
       "      <td>6.273</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">weighted</th>\n",
       "      <th rowspan=\"2\" valign=\"top\"></th>\n",
       "      <th>hmm</th>\n",
       "      <td>0.244</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.290</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mv</th>\n",
       "      <td>0.263</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.292</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           tok_precision  tok_recall  tok_f1 tok_cee tok_acc  \\\n",
       "label    proportion model                                                      \n",
       "ADJ      12.3 %     hmm            0.600       0.134   0.220                   \n",
       "                    mv             0.656       0.088   0.156                   \n",
       "DET      27.3 %     hmm            0.017       0.003   0.006                   \n",
       "                    mv             0.020       0.004   0.006                   \n",
       "NOUN     41.0 %     hmm            0.251       0.412   0.312                   \n",
       "                    mv             0.285       0.345   0.312                   \n",
       "NUM      4.2 %      hmm            1.000       0.734   0.846                   \n",
       "                    mv             0.988       0.734   0.842                   \n",
       "PROPN    15.2 %     hmm            0.136       0.932   0.238                   \n",
       "                    mv             0.122       0.955   0.216                   \n",
       "macro               hmm            0.401       0.443   0.420                   \n",
       "                    mv             0.414       0.425   0.420                   \n",
       "micro               hmm            0.196       0.359   0.254   6.394   0.312   \n",
       "                    mv             0.184       0.329   0.236   6.273   0.267   \n",
       "weighted            hmm            0.244       0.358   0.290                   \n",
       "                    mv             0.263       0.329   0.292                   \n",
       "\n",
       "                          coverage  ent_precision  ent_recall  ent_f1  \n",
       "label    proportion model                                              \n",
       "ADJ      12.3 %     hmm                     0.600       0.134   0.220  \n",
       "                    mv                      0.656       0.088   0.156  \n",
       "DET      27.3 %     hmm                     0.017       0.003   0.006  \n",
       "                    mv                      0.020       0.004   0.006  \n",
       "NOUN     41.0 %     hmm                     0.251       0.412   0.312  \n",
       "                    mv                      0.285       0.345   0.312  \n",
       "NUM      4.2 %      hmm                     1.000       0.734   0.846  \n",
       "                    mv                      0.988       0.734   0.842  \n",
       "PROPN    15.2 %     hmm                     0.136       0.932   0.238  \n",
       "                    mv                      0.122       0.955   0.216  \n",
       "macro               hmm                     0.401       0.443   0.420  \n",
       "                    mv                      0.414       0.425   0.420  \n",
       "micro               hmm      1.829          0.196       0.359   0.254  \n",
       "                    mv        1.79          0.184       0.329   0.236  \n",
       "weighted            hmm                     0.244       0.358   0.290  \n",
       "                    mv                      0.263       0.329   0.292  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f4302a27e3a6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Contrary, to the first part, we observe that the HMM performs better than majority vote."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
